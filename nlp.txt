Write in your own words named entity recognition.
--> it is a from or NLP, one of the most popular data preprocessing task, involves identification of key information in the text and classification into a set of predefined categories.
NER models is 2 step process- Detect a named entity and Categorize the entity
categories in architecture in NER are: Person, Organization, Place/ location.
The goal of NER is to automatically extract information from unstructured text
methods of ner are : train the model for multi-class classification using different machine learning algorithms, but it requires a lot of labelling., Conditional random field, 
deep Learning Based NER. For example, an NER machine learning (ML) model might detect the word “super.AI” in a text and classify it as a “Company”.
Example: Person:Rashi, Organization:Google, Time:2006, Location:Delhi.
Application: Human resources- Speed up the hiring process by summarizing applicants’ CVs
Customer support, Search and recommendation engines, Content classification, Health care, Academia.
Libabries used for NER are NLTK, SpaCy,Stanford NER.
NER can be used to improve the accuracy of other NLP tasks, such as part-of-speech tagging and dependency parsing.
-------------------------


What is difference between homonym and synonym and Give examples What is the purpose of Text summarization?
--> As nouns the difference between synonym and homonym is that: synonym is (semantics|with respect to a given word or phrase) a word or phrase with a meaning that is the same as, or very
similar to, another word or phrase. 
For eg: answer and response, intelligent and bright.
homonym is (semantics|strict sense) a word that both sounds and is spelled the same as another word but has a different meaning.
For eg: maid and made, ate and eight.

Text summarization is practice of breaking down long publications into manageable paragraphs or sentences. The procedure extracts important information while also ensuring
that the paragraph's sense is preserved. it is very useful and important part of Natural Language Processing (NLP)
We can summarize our text in a few lines by removing unimportant text and converting the same text into smaller semantic text form.
two approaches to text summarization: Extractive approaches and Abstractive approaches.
Applications:News article summaries, stock market reports, weather forecast reports, blogs, book/movie reviews.
It extracts vital information while preserving the meaning of the text, reducing the time required for grasping lengthy pieces such as articles without losing vital information.
Text summarization models automatically shorten documents, papers, podcasts, videos.
---------------------------


Give an example of Linguistic Morphology?
--> process of determining the morphemes from which a given word is constructed in natural language processing.
example: the word 'foxes' can be decomposed into 'fox' (the stem) and 'es' (a suffix indicating plurality).
Washing= wash + ing • Browser= browse + er • Rats= rat + s.
---------------------------


What is Hidden Markov Model used for? Give its purpose?
-->  very powerful statistical modeling tool used in speech recognition, handwriting recognition.
HMM model consist of these basic parts:
hidden states,  observation symbols (or states), transition from initial state to initial hidden state probability distribution, transition to terminal state probability distribution,
state transition probability distribution, state emission probability distribution.
It can be used to describe the evolution of observable events that depend on internal factors, which are not directly observable.
is used to explain or derive the probabilistic characteristic of any random process.
The main goal of HMM is to learn about a Markov chain by observing its hidden states.
it aims to recover the data sequence where the next sequence of the data can not be observed immediately but the next data depends on the old sequences.
Applications: Computational finance, speed analysis, Speech recognition, Speech synthesis, Part-of-speech tagging, Document separation in scanning solutions, Machine translation
Handwriting recognition, Time series analysis, Bioinformatics.
Limitations: Limited Modeling Capabilities, Overfitting, Lack of Robustness.
----------------------------


Give some examples of Noun Phrase and verb Phrase?
-->A declarative sentence consists of a noun phrase (the subject) and a verb phrase (the predicate). The verb phrase has a verb, followed (optionally, if the verb is transitive) by a 
noun phrase. A “noun phrase” is basically the noun, plus all of the stuff that surrounds and modifies the noun, like adjectives, relative clauses, prepositional phrases, etc.
eg: *Man* proposes, but *God* disposes(noun).
People: the soldier, Places: the house in the corner, things: this table.
The best car safety *device* is a rear-view *mirror*

eg:*Dress* smartly. *Arrive* on time.(verb)
Your camera *takes* fantastic pictures.
----------------------------


What is Adjectival phrase? Give some examples for the same.?
-->The beautiful girl is from London.(adjective)
The girl who is so beautiful is from London.(adjective phrase).
david is nuce, intelligent, smart boy.
------------------------------


What is the difference between hypernym and hyponym?
-->A hypernym describes a more broad term, for example cutlery, or dog.
A hyponym is a more specialised and specific word, for example: spoon would be a hyponym of cutlery and labrador would be a hyponym of dog.

a hyponym is a word or phrase whose semantic field is included within that of another word, its hypernym.For example, scarlet, vermilion, carmine, and crimson are all hyponyms of red,
which is, in turn, a hyponym of colour
A hypernym is a word that names a broad category that includes other words. ... Superhero is a hypernym for Batman and Spider-Man.
-----------------------------

word-collocations?
-->Collocations are two or more words that tend to appear frequently together, for example – United States. There are many other words that can come after United, such as the United 
Kingdom and United Airlines. As with many aspects of natural language processing, context is very important. And for collocations, context is everything. 
In the case of collocations, the context will be a document in the form of a list of words. Discovering collocations in this list of words means to find common phrases that occur 
frequently throughout the text.
Eg: *Correct*       *Incorrect*
    Heavy rain      Thick rain
    High temp.       Tall temp.
------------------------------


Word Sense Disambiguation (WSD) 
-->is a crucial method of Natural Language Processing (NLP) that helps to identify the intended meaning of a word in a given context. It involves identifying the correct sense of a word 
from a set of possible.
------------------------------



senses based on the context in which the word appears. WSD is a largely unconscious process in people










